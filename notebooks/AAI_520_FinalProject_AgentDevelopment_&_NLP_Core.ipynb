{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qq-W2xTQelP6"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Agent Processing System\n",
        "Multi-Agent Financial Analysis - Specialized LLM Agents\n",
        "Processes AAPL stock query with 4 specialized agents\n",
        "\"\"\"\n",
        "\n",
        "from openai import OpenAI\n",
        "from typing import Dict, List, Any\n",
        "from dataclasses import dataclass\n",
        "import json\n",
        "from datetime import datetime\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Alpha Vantage (already working)\n",
        "os.environ[\"ALPHAVANTAGE_API_KEY\"] = \"BVGUKZR1MHVS0T6B\"\n",
        "\n",
        "# OpenAI (ADD YOUR KEY HERE)\n",
        "os.environ[\"OPENAI_API_KEY\"] =  \"sk-proj-\" # your openAI key here\n",
        "\n",
        "client = OpenAI(api_key= \"sk-proj-\") # your openAI key here\n",
        "print(\"✓ API keys configured\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZkM5OWfBJZ2",
        "outputId": "a9196e19-8b4b-4017-d5c8-3ac436001c71"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ API keys configured\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class AgentResponse:\n",
        "    \"\"\"Standard response format from all agents\"\"\"\n",
        "    agent_name: str                  # Which agent produced this (e.g., \"News Analysis Agent\")\n",
        "    analysis: str                    # The actual text analysis/recommendation\n",
        "    score: float                     # -1(very negative) to +1 scale (very positive)\n",
        "    confidence: float                # How confident: 0 (not confident) to 1 (very confident)\n",
        "    key_factors: List[str]           # Bullet points of important findings\n",
        "    timestamp: str                   # When the analysis was done"
      ],
      "metadata": {
        "id": "8SgdltfIf9og"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseAgent:\n",
        "    \"\"\"Base class for all financial agents\"\"\"\n",
        "\n",
        "    def __init__(self, agent_name: str, model: str = \"gpt-4\"):\n",
        "        self.agent_name = agent_name # Stores the agent's name\n",
        "        self.model = model    # Which AI model to use (default: GPT-4)\n",
        "        self.memory = []   # Empty list to store conversation history\n",
        "\n",
        "    def call_llm(self, system_prompt: str, user_message: str) -> str:\n",
        "        \"\"\"Call LLM with error handling\"\"\"\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": system_prompt}, #Instructions telling the AI how to behave\n",
        "                    {\"role\": \"user\", \"content\": user_message}  #The actual data/question to analyze\n",
        "                ],\n",
        "                temperature=0.3,  # Lower temperature for more consistent analysis\n",
        "                max_tokens=800     #limits response length\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            print(f\"Error in {self.agent_name}: {str(e)}\")\n",
        "            return f\"Error processing request: {str(e)}\"\n",
        "\n",
        "    # Add to BaseAgent class\n",
        "    def add_to_memory(self, interaction):\n",
        "      \"\"\"Store conversation history\"\"\"\n",
        "      self.memory.append({\n",
        "        'timestamp': datetime.now(),\n",
        "        'input': interaction['input'],\n",
        "        'output': interaction['output']\n",
        "        })\n",
        "\n",
        "    def get_context(self, last_n=5):\n",
        "      \"\"\"Retrieve recent context\"\"\"\n",
        "      return self.memory[-last_n:]\n",
        "\n",
        "    def process(self, data: Dict[str, Any]) -> AgentResponse:\n",
        "        \"\"\"Override in each specialized agent\"\"\"\n",
        "        raise NotImplementedError(\"Each agent must implement process method\")"
      ],
      "metadata": {
        "id": "gMd5G_3XmJFE"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NewsAnalysisAgent\n",
        "This agent reads news headlines about a stock, asks GPT-4 \"are these headlines good or bad news?\", gets back a sentiment score, and packages it in a standardized format for the orchestrator to use.\n",
        "For example: if someone whats get sentiment from new, this agent is  reading news and telling if it's bullish or bearish."
      ],
      "metadata": {
        "id": "GRPVe9rr4sNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsAnalysisAgent(BaseAgent):\n",
        "    \"\"\"Analyzes financial news sentiment and impact\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(\"News Analysis Agent\")\n",
        "        self.system_prompt = \"\"\"You are a financial news analyst specializing in sentiment analysis.\n",
        "Analyze news articles about companies and provide:\n",
        "1. Overall sentiment score (-1 to +1, where -1 is very negative, 0 is neutral, +1 is very positive)\n",
        "2. Key factors driving the sentiment\n",
        "3. Potential impact on stock price\n",
        "\n",
        "Be objective and consider both positive and negative aspects.\n",
        "Return response in JSON format with keys: sentiment_score, analysis, key_factors, confidence\"\"\"\n",
        "\n",
        "    def process(self, data: Dict[str, Any]) -> AgentResponse:\n",
        "        \"\"\"Process news data for sentiment analysis\"\"\"\n",
        "        ticker = data.get('ticker', 'AAPL')\n",
        "        news_articles = data.get('news', [])\n",
        "\n",
        "        news_summary = \"\\n\".join([\n",
        "            f\"- {article.get('title', '')}: {article.get('summary', '')}\"\n",
        "            for article in news_articles[:5]\n",
        "        ])\n",
        "\n",
        "        user_message = f\"\"\"Analyze the following recent news about {ticker}:\n",
        "\n",
        "{news_summary}\n",
        "\n",
        "Provide sentiment analysis and impact assessment.\"\"\"\n",
        "\n",
        "        llm_response = self.call_llm(self.system_prompt, user_message)\n",
        "\n",
        "        # SAFE PARSING\n",
        "        try:\n",
        "            result = json.loads(llm_response)\n",
        "            score = result.get('sentiment_score', 0)\n",
        "            analysis = result.get('analysis', llm_response)\n",
        "            key_factors = result.get('key_factors', [])\n",
        "\n",
        "            # Safe confidence extraction\n",
        "            confidence_raw = result.get('confidence', 0.7)\n",
        "            try:\n",
        "                confidence = max(0.0, min(1.0, float(confidence_raw)))\n",
        "            except (ValueError, TypeError):\n",
        "                confidence = 0.7\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            score = 0\n",
        "            analysis = llm_response\n",
        "            key_factors = [\"Unable to parse structured response\"]\n",
        "            confidence = 0.5\n",
        "\n",
        "        return AgentResponse(\n",
        "            agent_name=self.agent_name,\n",
        "            analysis=analysis,\n",
        "            score=float(score),\n",
        "            confidence=float(confidence),\n",
        "            key_factors=key_factors,\n",
        "            timestamp=datetime.now().isoformat()\n",
        "        )"
      ],
      "metadata": {
        "id": "gpyVj0_4GrQs"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EarningsAnalysisAgent\n",
        "The Earnings Analysis Agent examines a company's financial performance (revenue, profits, earnings per share) and determines if the fundamentals are strong by comparing actual results against analyst expectations. It sends this financial data to GPT-4, which returns a score (-1 to +1) indicating whether the company's financials suggest it's a good or weak investment."
      ],
      "metadata": {
        "id": "HTlIGaGI76kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarningsAnalysisAgent(BaseAgent):\n",
        "    \"\"\"Analyzes earnings reports and financial statements\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(\"Earnings Analysis Agent\")\n",
        "        self.system_prompt = \"\"\"You are a financial analyst specializing in earnings and fundamental analysis.\n",
        "Analyze company financial data and provide:\n",
        "1. Fundamental strength score (-1 to +1, where -1 is very weak, +1 is very strong)\n",
        "2. Key financial metrics analysis (revenue, earnings, growth)\n",
        "3. Comparison to expectations\n",
        "4. Important trends\n",
        "\n",
        "Return response in JSON format with keys: fundamental_score, analysis, key_factors, confidence\"\"\"\n",
        "\n",
        "    def process(self, data: Dict[str, Any]) -> AgentResponse:  # Fixed indentation\n",
        "        \"\"\"Process earnings and financial data\"\"\"\n",
        "        ticker = data.get('ticker', 'UNKNOWN')\n",
        "        financials = data.get('financials', {})\n",
        "\n",
        "        # Prepare financial summary\n",
        "        financial_summary = f\"\"\"\n",
        "Company: {ticker}\n",
        "Revenue: ${financials.get('revenue', 'N/A')}B\n",
        "EPS: ${financials.get('eps', 'N/A')}\n",
        "Revenue Growth: {financials.get('revenue_growth', 'N/A')}%\n",
        "Profit Margin: {financials.get('profit_margin', 'N/A')}%\n",
        "Expected Revenue: ${financials.get('expected_revenue', 'N/A')}B\n",
        "Expected EPS: ${financials.get('expected_eps', 'N/A')}\n",
        "\"\"\"\n",
        "\n",
        "        user_message = f\"\"\"Analyze the following financial data for {ticker}:\n",
        "\n",
        "{financial_summary}\n",
        "\n",
        "Assess fundamental strength and growth prospects.\"\"\"\n",
        "\n",
        "        llm_response = self.call_llm(self.system_prompt, user_message)\n",
        "\n",
        "        # SAFE PARSING\n",
        "        try:\n",
        "            result = json.loads(llm_response)\n",
        "            score = result.get('fundamental_score', 0)  # Note: fundamental_score, not sentiment_score\n",
        "            analysis = result.get('analysis', llm_response)\n",
        "            key_factors = result.get('key_factors', [])\n",
        "\n",
        "            # Safe confidence extraction\n",
        "            confidence_raw = result.get('confidence', 0.8)\n",
        "            try:\n",
        "                confidence = max(0.0, min(1.0, float(confidence_raw)))\n",
        "            except (ValueError, TypeError):\n",
        "                confidence = 0.8\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            score = 0\n",
        "            analysis = llm_response\n",
        "            key_factors = [\"Unable to parse structured response\"]\n",
        "            confidence = 0.6\n",
        "\n",
        "        return AgentResponse(\n",
        "            agent_name=self.agent_name,\n",
        "            analysis=analysis,\n",
        "            score=float(score),\n",
        "            confidence=float(confidence),\n",
        "            key_factors=key_factors,\n",
        "            timestamp=datetime.now().isoformat()\n",
        "        )"
      ],
      "metadata": {
        "id": "_k59h-PMETq5"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MarketSignalsAgent\n",
        "The MarketSignalsAgent performs technical analysis by examining stock price patterns, trading volume, and technical indicators (like moving averages, RSI, MACD) to identify trends and momentum. It sends this technical data to GPT-4, which returns a score (-1 to +1) indicating whether the stock's price action suggests a bullish or bearish trend based on chart patterns and trading signals."
      ],
      "metadata": {
        "id": "AhddYSSS8-OH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MarketSignalsAgent(BaseAgent):\n",
        "    \"\"\"Performs technical analysis on market data\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(\"Market Signals Agent\")\n",
        "        self.system_prompt = \"\"\"You are a technical analyst specializing in market signals and price patterns.\n",
        "Analyze technical indicators and provide:\n",
        "1. Technical strength score (-1 to +1, where -1 is very bearish, +1 is very bullish)\n",
        "2. Key technical indicators assessment\n",
        "3. Support and resistance levels\n",
        "4. Trend analysis\n",
        "\n",
        "Return response in JSON format with keys: technical_score, analysis, key_factors, confidence\"\"\"\n",
        "\n",
        "    def process(self, data: Dict[str, Any]) -> AgentResponse:\n",
        "        \"\"\"Process technical market data\"\"\"\n",
        "        ticker = data.get('ticker', 'UNKNOWN')\n",
        "        technicals = data.get('technicals', {})\n",
        "\n",
        "        technical_summary = f\"\"\"\n",
        "Ticker: {ticker}\n",
        "Current Price: ${technicals.get('current_price', 'N/A')}\n",
        "50-day MA: ${technicals.get('ma_50', 'N/A')}\n",
        "200-day MA: ${technicals.get('ma_200', 'N/A')}\n",
        "RSI: {technicals.get('rsi', 'N/A')}\n",
        "MACD: {technicals.get('macd', 'N/A')}\n",
        "Volume: {technicals.get('volume', 'N/A')} (Avg: {technicals.get('avg_volume', 'N/A')})\n",
        "Support: ${technicals.get('support', 'N/A')}\n",
        "Resistance: ${technicals.get('resistance', 'N/A')}\n",
        "\"\"\"\n",
        "\n",
        "        user_message = f\"\"\"Analyze the following technical data for {ticker}:\n",
        "\n",
        "{technical_summary}\n",
        "\n",
        "Assess technical strength and price momentum.\"\"\"\n",
        "\n",
        "        llm_response = self.call_llm(self.system_prompt, user_message)\n",
        "\n",
        "        # SAFE PARSING\n",
        "        try:\n",
        "            result = json.loads(llm_response)\n",
        "            score = result.get('technical_score', 0)\n",
        "            analysis = result.get('analysis', llm_response)\n",
        "            key_factors = result.get('key_factors', [])\n",
        "\n",
        "            # Safe confidence extraction\n",
        "            confidence_raw = result.get('confidence', 0.7)\n",
        "            try:\n",
        "                confidence = max(0.0, min(1.0, float(confidence_raw)))\n",
        "            except (ValueError, TypeError):\n",
        "                confidence = 0.7\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            score = 0\n",
        "            analysis = llm_response\n",
        "            key_factors = [\"Unable to parse structured response\"]\n",
        "            confidence = 0.5\n",
        "\n",
        "        return AgentResponse(\n",
        "            agent_name=self.agent_name,\n",
        "            analysis=analysis,\n",
        "            score=float(score),\n",
        "            confidence=float(confidence),\n",
        "            key_factors=key_factors,\n",
        "            timestamp=datetime.now().isoformat()\n",
        "        )"
      ],
      "metadata": {
        "id": "buLNjNZBG-ZY"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RiskAssessmentAgent\n",
        "The RiskAssessmentAgent evaluates investment risk by analyzing metrics like beta (volatility), Value at Risk, Sharpe ratio, and sector correlation to determine how risky a stock is for a portfolio. It sends these risk metrics to GPT-4, which returns a risk score (0 to 1, where 0 is low risk and 1 is high risk) along with warnings about potential portfolio concentration or volatility issues."
      ],
      "metadata": {
        "id": "JCEvRRdh8lyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RiskAssessmentAgent(BaseAgent):\n",
        "    \"\"\"Assesses investment risk and portfolio fit\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(\"Risk Assessment Agent\")\n",
        "        self.system_prompt = \"\"\"You are a risk management analyst specializing in portfolio risk assessment.\n",
        "Analyze risk metrics and provide:\n",
        "1. Risk level score (0 to 1, where 0 is very low risk, 1 is very high risk)\n",
        "2. Key risk factors\n",
        "3. Portfolio diversification implications\n",
        "4. Risk-adjusted return assessment\n",
        "\n",
        "Return response in JSON format with keys: risk_score, analysis, key_factors, confidence\"\"\"\n",
        "\n",
        "    def process(self, data: Dict[str, Any]) -> AgentResponse:\n",
        "        \"\"\"Process risk metrics\"\"\"\n",
        "        ticker = data.get('ticker', 'UNKNOWN')\n",
        "        risk_data = data.get('risk_metrics', {})\n",
        "\n",
        "        risk_summary = f\"\"\"\n",
        "Ticker: {ticker}\n",
        "Beta: {risk_data.get('beta', 'N/A')}\n",
        "Volatility (30-day): {risk_data.get('volatility', 'N/A')}%\n",
        "Value at Risk (5%): ${risk_data.get('var_5', 'N/A')}\n",
        "Sharpe Ratio: {risk_data.get('sharpe_ratio', 'N/A')}\n",
        "Max Drawdown: {risk_data.get('max_drawdown', 'N/A')}%\n",
        "Sector Correlation: {risk_data.get('sector_correlation', 'N/A')}\n",
        "P/E Ratio: {risk_data.get('pe_ratio', 'N/A')}\n",
        "\"\"\"\n",
        "\n",
        "        user_message = f\"\"\"Analyze the following risk metrics for {ticker}:\n",
        "\n",
        "{risk_summary}\n",
        "\n",
        "Assess overall investment risk and portfolio implications.\"\"\"\n",
        "\n",
        "        llm_response = self.call_llm(self.system_prompt, user_message)\n",
        "\n",
        "        # SAFE PARSING\n",
        "        try:\n",
        "            result = json.loads(llm_response)\n",
        "            score = result.get('risk_score', 0.5)\n",
        "            analysis = result.get('analysis', llm_response)\n",
        "            key_factors = result.get('key_factors', [])\n",
        "\n",
        "            # Safe confidence extraction\n",
        "            confidence_raw = result.get('confidence', 0.8)\n",
        "            try:\n",
        "                confidence = max(0.0, min(1.0, float(confidence_raw)))\n",
        "            except (ValueError, TypeError):\n",
        "                confidence = 0.8\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            score = 0.5\n",
        "            analysis = llm_response\n",
        "            key_factors = [\"Unable to parse structured response\"]\n",
        "            confidence = 0.6\n",
        "\n",
        "        return AgentResponse(\n",
        "            agent_name=self.agent_name,\n",
        "            analysis=analysis,\n",
        "            score=float(score),\n",
        "            confidence=float(confidence),\n",
        "            key_factors=key_factors,\n",
        "            timestamp=datetime.now().isoformat()\n",
        "        )"
      ],
      "metadata": {
        "id": "eD0MRrmWHQm3"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SynthesisAgent\n",
        "The SynthesisAgent acts as the \"decision maker\" that takes all the individual agent analyses (news sentiment, earnings strength, technical signals, risk level) and combines them into a single investment recommendation (STRONG BUY, BUY, HOLD, SELL, STRONG SELL). It sends a summary of all agent scores and findings to GPT-4, which weighs the different perspectives and returns a final actionable recommendation with confidence level and supporting reasoning."
      ],
      "metadata": {
        "id": "ohn9ZLZ0jG0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SynthesisAgent(BaseAgent):\n",
        "    \"\"\"Combines insights from all agents into final recommendation\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialize with base agent functionality\n",
        "        super().__init__(\"Research Synthesis Agent\")\n",
        "        # Define instructions for the AI on how to synthesize multiple analyses\n",
        "        self.system_prompt = \"\"\"You are a senior investment analyst who synthesizes multiple analyses into actionable recommendations.\n",
        "Given analyses from news, earnings, technical, and risk agents, provide:\n",
        "1. Overall investment recommendation (STRONG BUY, BUY, HOLD, SELL, STRONG SELL)\n",
        "2. Confidence level (0 to 1)\n",
        "3. Key reasoning\n",
        "4. Risk considerations\n",
        "5. Target price range (if applicable)\n",
        "\n",
        "Return response in JSON format with keys: recommendation, confidence, analysis, key_points, risks\"\"\"\n",
        "\n",
        "    def process(self, agent_responses: List[AgentResponse]) -> AgentResponse:\n",
        "        \"\"\"Synthesize all agent responses\"\"\"\n",
        "        analyses_summary = \"\\n\\n\".join([\n",
        "            f\"{resp.agent_name}:\\n\"\n",
        "            f\"Score: {resp.score}\\n\"\n",
        "            f\"Analysis: {resp.analysis}\\n\"\n",
        "            f\"Key Factors: {', '.join(resp.key_factors)}\"\n",
        "            for resp in agent_responses\n",
        "        ])\n",
        "\n",
        "        user_message = f\"\"\"Synthesize the following analyses into a final investment recommendation:\n",
        "\n",
        "{analyses_summary}\n",
        "\n",
        "Provide comprehensive investment recommendation with supporting reasoning.\"\"\"\n",
        "\n",
        "        llm_response = self.call_llm(self.system_prompt, user_message)\n",
        "\n",
        "        # SAFE PARSING\n",
        "        try:\n",
        "            result = json.loads(llm_response)\n",
        "            recommendation = result.get('recommendation', 'HOLD')\n",
        "            analysis = result.get('analysis', llm_response)\n",
        "            key_factors = result.get('key_points', [])\n",
        "\n",
        "            # Safe confidence extraction\n",
        "            confidence_raw = result.get('confidence', 0.7)\n",
        "            try:\n",
        "                confidence = max(0.0, min(1.0, float(confidence_raw)))\n",
        "            except (ValueError, TypeError):\n",
        "                confidence = 0.7\n",
        "\n",
        "            # Convert recommendation to score\n",
        "            rec_to_score = {\n",
        "                'STRONG BUY': 1.0,\n",
        "                'BUY': 0.6,\n",
        "                'HOLD': 0.0,\n",
        "                'SELL': -0.6,\n",
        "                'STRONG SELL': -1.0\n",
        "            }\n",
        "            score = rec_to_score.get(recommendation, 0.0)\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            score = 0\n",
        "            analysis = llm_response\n",
        "            key_factors = [\"Unable to parse structured response\"]\n",
        "            confidence = 0.6\n",
        "\n",
        "        return AgentResponse(\n",
        "            agent_name=self.agent_name,\n",
        "            analysis=analysis,\n",
        "            score=float(score),\n",
        "            confidence=float(confidence),\n",
        "            key_factors=key_factors,\n",
        "            timestamp=datetime.now().isoformat()\n",
        "        )"
      ],
      "metadata": {
        "id": "07G2q9eGHdH-"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CritiqueAgent\n",
        "\n",
        "The CritiqueAgent acts as a \"quality control checker\" that reviews the final investment recommendation to catch mistakes, biases, or missing information before presenting it to the user. It examines the SynthesisAgent's recommendation, asks GPT-4 to identify logical flaws or gaps in reasoning, and can adjust the confidence level downward if it finds issues (like  \"didn't consider macroeconomic factors\"), ensuring the final output is reliable and well-reasoned.\n"
      ],
      "metadata": {
        "id": "NjnZdPHAkxys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CritiqueAgent(BaseAgent):\n",
        "    \"\"\"Reviews and validates analysis quality\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(\"Critique & Validation Agent\")\n",
        "        self.system_prompt = \"\"\"You are critique analyst who reviews investment recommendations for biases, logical errors, and completeness.\n",
        "Review the synthesis and identify:\n",
        "1. Logical inconsistencies\n",
        "2. Potential biases\n",
        "3. Missing considerations\n",
        "4. Data quality issues\n",
        "5. Confidence adjustment recommendation\n",
        "\n",
        "Return response in JSON format with keys: quality_score, issues_found, suggestions, adjusted_confidence\"\"\"\n",
        "\n",
        "    def process(self, synthesis_response: AgentResponse) -> AgentResponse:\n",
        "        \"\"\"Critique the synthesis\"\"\"\n",
        "        user_message = f\"\"\"Review this investment analysis for quality and completeness:\n",
        "\n",
        "Recommendation: {synthesis_response.analysis}\n",
        "Confidence: {synthesis_response.confidence}\n",
        "Key Factors: {', '.join(synthesis_response.key_factors)}\n",
        "\n",
        "Identify any issues, biases, or missing elements.\"\"\"\n",
        "\n",
        "        llm_response = self.call_llm(self.system_prompt, user_message)\n",
        "\n",
        "        # SAFE PARSING\n",
        "        try:\n",
        "            result = json.loads(llm_response)\n",
        "            quality_score = result.get('quality_score', 0.7)\n",
        "            issues = result.get('issues_found', [])\n",
        "            suggestions = result.get('suggestions', [])\n",
        "            adjusted_confidence_raw = result.get('adjusted_confidence', synthesis_response.confidence)\n",
        "\n",
        "            # Safe confidence extraction\n",
        "            try:\n",
        "                adjusted_confidence = max(0.0, min(1.0, float(adjusted_confidence_raw)))\n",
        "            except (ValueError, TypeError):\n",
        "                adjusted_confidence = synthesis_response.confidence\n",
        "\n",
        "            analysis = f\"Quality Score: {quality_score}\\n\"\n",
        "            if issues:\n",
        "                analysis += f\"Issues Found: {', '.join(issues)}\\n\"\n",
        "            if suggestions:\n",
        "                analysis += f\"Suggestions: {', '.join(suggestions)}\"\n",
        "\n",
        "            key_factors = issues if issues else [\"No major issues found\"]\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            quality_score = 0.7\n",
        "            analysis = llm_response\n",
        "            adjusted_confidence = synthesis_response.confidence\n",
        "            key_factors = [\"Unable to parse structured response\"]\n",
        "\n",
        "        return AgentResponse(\n",
        "            agent_name=self.agent_name,\n",
        "            analysis=analysis,\n",
        "            score=float(quality_score),\n",
        "            confidence=float(adjusted_confidence),\n",
        "            key_factors=key_factors,\n",
        "            timestamp=datetime.now().isoformat()\n",
        "        )"
      ],
      "metadata": {
        "id": "3Myr_MR6Hphk"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"notebooks/01_data_ingestion.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1J_syHGmJHhA8XcAtxw7nQ0KPWMJbnSkd\n",
        "\"\"\"\n",
        "\n",
        "#import os\n",
        "os.environ[\"ALPHAVANTAGE_API_KEY\"] = \"BVGUKZR1MHVS0T6B\"\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from datasets import Dataset\n",
        "\n",
        "# ------------------------------\n",
        "# Helper: Convert Pandas → Hugging Face Dataset\n",
        "# ------------------------------\n",
        "def to_hf(df, schema=None):\n",
        "    \"\"\"Convert a pandas DataFrame to a Hugging Face Dataset. Handles empty gracefully.\"\"\"\n",
        "    if df is None or getattr(df, \"empty\", True):\n",
        "        if schema:\n",
        "            return Dataset.from_dict({c: [] for c in schema})\n",
        "        return Dataset.from_dict({})\n",
        "    if schema:\n",
        "        df = df[[c for c in schema if c in df.columns]].copy()\n",
        "    return Dataset.from_pandas(df.reset_index(drop=True), preserve_index=False)\n",
        "\n",
        "# ------------------------------\n",
        "# Alpha Vantage Connector (for news + indicators only)\n",
        "# ------------------------------\n",
        "class AlphaConnector:\n",
        "    def __init__(self, api_key=None):\n",
        "        # Pick up API key from os.environ if not passed directly\n",
        "        self.api_key = api_key or os.getenv(\"ALPHAVANTAGE_API_KEY\")\n",
        "        if not self.api_key:\n",
        "            raise ValueError(\"Alpha Vantage API key not found. Set os.environ['ALPHAVANTAGE_API_KEY'].\")\n",
        "\n",
        "        self.base_url = \"https://www.alphavantage.co/query\"\n",
        "\n",
        "    def fetch_news(self, symbol):\n",
        "        \"\"\"Fetch company news & sentiment (Alpha Vantage).\"\"\"\n",
        "        params = {\n",
        "            \"function\": \"NEWS_SENTIMENT\",\n",
        "            \"tickers\": symbol,\n",
        "            \"apikey\": self.api_key\n",
        "        }\n",
        "        r = requests.get(self.base_url, params=params)\n",
        "        data = r.json()\n",
        "\n",
        "        if \"feed\" not in data:\n",
        "            print(\"No news data:\", data)\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        rows = []\n",
        "        for item in data[\"feed\"]:\n",
        "            rows.append({\n",
        "                \"published_at\": item.get(\"time_published\"),\n",
        "                \"source\": item.get(\"source\"),\n",
        "                \"title\": item.get(\"title\"),\n",
        "                \"summary\": item.get(\"summary\"),\n",
        "                \"url\": item.get(\"url\"),\n",
        "                \"overall_sentiment\": item.get(\"overall_sentiment_label\"),\n",
        "                # ** Added By Ali **\n",
        "                \"overall_sentiment_score\": item.get(\"overall_sentiment_score\") # both label and score so later agents (NewsAnalysisAgent, SynthesisAgent, etc.) can use either\n",
        "            })\n",
        "        return pd.DataFrame(rows)\n",
        "\n",
        "    def fetch_indicator(self, symbol, indicator, interval=\"daily\", time_period=14, series_type=\"close\"):\n",
        "        \"\"\"Generic technical indicator fetch (SMA, RSI, MACD).\"\"\"\n",
        "        params = {\n",
        "            \"function\": indicator,\n",
        "            \"symbol\": symbol,\n",
        "            \"interval\": interval,\n",
        "            \"time_period\": time_period,\n",
        "            \"series_type\": series_type,\n",
        "            \"apikey\": self.api_key\n",
        "        }\n",
        "        r = requests.get(self.base_url, params=params)\n",
        "        data = r.json()\n",
        "\n",
        "        key_map = {\n",
        "            \"SMA\": \"Technical Analysis: SMA\",\n",
        "            \"RSI\": \"Technical Analysis: RSI\",\n",
        "            \"MACD\": \"Technical Analysis: MACD\"\n",
        "        }\n",
        "        key = key_map.get(indicator)\n",
        "        if key not in data:\n",
        "            print(f\"{indicator} fetch failed:\", data)\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        df = pd.DataFrame.from_dict(data[key], orient=\"index\")\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        df.reset_index(inplace=True)\n",
        "        df = df.rename(columns={\"index\": \"date\"})\n",
        "\n",
        "        # Cast numeric values\n",
        "        for col in df.columns:\n",
        "            if col != \"date\":\n",
        "                df[col] = df[col].astype(float)\n",
        "\n",
        "        return df\n",
        "\n",
        "# ------------------------------\n",
        "# Data Ingestion Manager\n",
        "# ------------------------------\n",
        "class DataIngestionManager:\n",
        "    def __init__(self, api_key=None):\n",
        "        self.alpha = AlphaConnector(api_key)\n",
        "\n",
        "    def fetch_all(self, symbol, start=None, end=None):\n",
        "        \"\"\"Fetch prices (Yahoo), news (Alpha Vantage), SMA, RSI (Alpha Vantage).\"\"\"\n",
        "        datasets = {}\n",
        "\n",
        "        # Prices from Yahoo Finance (unlimited)\n",
        "        try:\n",
        "            df_prices = yf.download(symbol, start=start, end=end, progress=False)\n",
        "\n",
        "            # Flatten MultiIndex columns if necessary\n",
        "            if isinstance(df_prices.columns, pd.MultiIndex):\n",
        "                df_prices.columns = [c[0].lower() for c in df_prices.columns]\n",
        "\n",
        "            df_prices = df_prices.reset_index().rename(columns={\n",
        "                \"Date\": \"date\",\n",
        "                \"open\": \"open\",\n",
        "                \"high\": \"high\",\n",
        "                \"low\": \"low\",\n",
        "                \"close\": \"close\",\n",
        "                \"adj close\": \"adj_close\",\n",
        "                \"volume\": \"volume\"\n",
        "            })\n",
        "            df_prices[\"date\"] = df_prices[\"date\"].astype(str)\n",
        "\n",
        "            datasets[\"prices\"] = to_hf(\n",
        "                df_prices, schema=[\"date\",\"open\",\"high\",\"low\",\"close\",\"adj_close\",\"volume\"]\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(\"Yahoo Finance fetch failed:\", e)\n",
        "            datasets[\"prices\"] = to_hf(pd.DataFrame(), schema=[\"date\",\"open\",\"high\",\"low\",\"close\",\"adj_close\",\"volume\"])\n",
        "\n",
        "        # News from Alpha Vantage\n",
        "        datasets[\"news\"] = to_hf(\n",
        "            self.alpha.fetch_news(symbol),\n",
        "            schema=[\"published_at\",\"source\",\"title\",\"summary\",\"url\",\"overall_sentiment\"]\n",
        "        )\n",
        "\n",
        "        # Technical Indicators from Alpha Vantage\n",
        "        datasets[\"sma\"] = to_hf(\n",
        "            self.alpha.fetch_indicator(symbol, \"SMA\", time_period=20),\n",
        "            schema=[\"date\",\"SMA\"]\n",
        "        )\n",
        "        datasets[\"rsi\"] = to_hf(\n",
        "            self.alpha.fetch_indicator(symbol, \"RSI\", time_period=14),\n",
        "            schema=[\"date\",\"RSI\"]\n",
        "        )\n",
        "\n",
        "        # Removed MACD to avoid premium-only error\n",
        "        return datasets\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "mgr = DataIngestionManager()  # will pick up the key from os.environ\n",
        "symbol = \"AAPL\"\n",
        "start = (datetime.now() - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
        "end   = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "datasets = mgr.fetch_all(symbol, start, end)\n",
        "\n",
        "print(\"Prices sample:\")\n",
        "print(datasets[\"prices\"].to_pandas().head())\n",
        "\n",
        "print(\"News sample:\")\n",
        "print(datasets[\"news\"].to_pandas().head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvXsw-Yb3VUn",
        "outputId": "a4aeab86-adea-45b1-e60a-0cc228f811ad"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4032339001.py:120: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df_prices = yf.download(symbol, start=start, end=end, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No news data: {'Information': 'We have detected your API key as BVGUKZR1MHVS0T6B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n",
            "SMA fetch failed: {'Information': 'We have detected your API key as BVGUKZR1MHVS0T6B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n",
            "RSI fetch failed: {'Information': 'We have detected your API key as BVGUKZR1MHVS0T6B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n",
            "Prices sample:\n",
            "         date        open        high         low       close     volume\n",
            "0  2025-09-15  237.000000  238.190002  235.029999  236.699997   42699500\n",
            "1  2025-09-16  237.179993  241.220001  236.320007  238.149994   63421100\n",
            "2  2025-09-17  238.970001  240.100006  237.729996  238.990005   46508000\n",
            "3  2025-09-18  239.970001  241.199997  236.649994  237.880005   44249600\n",
            "4  2025-09-19  241.229996  246.300003  240.210007  245.500000  163741300\n",
            "News sample:\n",
            "Empty DataFrame\n",
            "Columns: [published_at, source, title, summary, url, overall_sentiment]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# INTEGRATION TEST CELL\n",
        "# ============================================================================\n",
        "\n",
        "def test_engineer1_engineer3_integration():\n",
        "    \"\"\"Test Engineer 1's real data with Engineer 3's real agents\"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"INTEGRATION TEST - Engineer 1 + Engineer 3\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Get data from Engineer 1\n",
        "    print(\"\\n[STEP 1] Fetching real data...\")\n",
        "    from datetime import datetime, timedelta\n",
        "\n",
        "    mgr = DataIngestionManager()\n",
        "    symbol = \"AAPL\"\n",
        "    start = (datetime.now() - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
        "    end = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    datasets = mgr.fetch_all(symbol, start, end)\n",
        "    print(f\"✓ Fetched data for {symbol}\")\n",
        "\n",
        "    # Convert to agent format\n",
        "    print(\"\\n[STEP 2] Preparing data for agents...\")\n",
        "    news_df = datasets[\"news\"].to_pandas()\n",
        "    prices_df = datasets[\"prices\"].to_pandas()\n",
        "    sma_df = datasets[\"sma\"].to_pandas()\n",
        "    rsi_df = datasets[\"rsi\"].to_pandas()\n",
        "\n",
        "    # News input\n",
        "    news_articles = news_df.head(5).to_dict('records')\n",
        "    news_input = {'ticker': symbol, 'news': news_articles}\n",
        "\n",
        "    # Technical input\n",
        "    latest_price = prices_df.iloc[-1] if len(prices_df) > 0 else {}\n",
        "    latest_sma = sma_df.iloc[-1] if len(sma_df) > 0 else {}\n",
        "    latest_rsi = rsi_df.iloc[-1] if len(rsi_df) > 0 else {}\n",
        "\n",
        "    technicals_input = {\n",
        "        'ticker': symbol,\n",
        "        'technicals': {\n",
        "            'current_price': str(latest_price.get('close', 'N/A')),\n",
        "            'ma_50': str(latest_sma.get('SMA', 'N/A')),\n",
        "            'rsi': str(latest_rsi.get('RSI', 'N/A')),\n",
        "            'volume': str(latest_price.get('volume', 'N/A'))\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Financial input (mock for now)\n",
        "    financials_input = {\n",
        "        'ticker': symbol,\n",
        "        'financials': {\n",
        "            'revenue': '394.3',\n",
        "            'eps': '6.42',\n",
        "            'revenue_growth': '15.0',\n",
        "            'profit_margin': '26.3'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Risk input (mock for now)\n",
        "    risk_input = {\n",
        "        'ticker': symbol,\n",
        "        'risk_metrics': {\n",
        "            'beta': '1.15',\n",
        "            'volatility': '22.5',\n",
        "            'sharpe_ratio': '1.35'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(\"✓ Data prepared\")\n",
        "\n",
        "    # Test agents\n",
        "    print(\"\\n[STEP 3] Testing agents with REAL OpenAI...\")\n",
        "\n",
        "    news_agent = NewsAnalysisAgent()\n",
        "    news_resp = news_agent.process(news_input)\n",
        "    print(f\"✓ News: {news_resp.score:.2f}\")\n",
        "\n",
        "    earnings_agent = EarningsAnalysisAgent()\n",
        "    earn_resp = earnings_agent.process(financials_input)\n",
        "    print(f\"✓ Earnings: {earn_resp.score:.2f}\")\n",
        "\n",
        "    market_agent = MarketSignalsAgent()\n",
        "    market_resp = market_agent.process(technicals_input)\n",
        "    print(f\"✓ Market: {market_resp.score:.2f}\")\n",
        "\n",
        "    risk_agent = RiskAssessmentAgent()\n",
        "    risk_resp = risk_agent.process(risk_input)\n",
        "    print(f\"✓ Risk: {risk_resp.score:.2f}\")\n",
        "\n",
        "    # Synthesize\n",
        "    print(\"\\n[STEP 4] Synthesizing recommendation...\")\n",
        "    synthesis_agent = SynthesisAgent()\n",
        "    all_responses = [news_resp, earn_resp, market_resp, risk_resp]\n",
        "    final_resp = synthesis_agent.process(all_responses)\n",
        "    print(f\"✓ Final Score: {final_resp.score:.2f}\")\n",
        "\n",
        "    # Critique\n",
        "    print(\"\\n[STEP 5] Critiquing analysis...\")\n",
        "    critique_agent = CritiqueAgent()\n",
        "    critique_resp = critique_agent.process(final_resp)\n",
        "    print(f\"✓ Quality: {critique_resp.score:.2f}\")\n",
        "\n",
        "    # Results\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"FINAL RESULTS\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\nTicker: {symbol}\")\n",
        "    print(f\"\\nAgent Scores:\")\n",
        "    for resp in all_responses:\n",
        "        print(f\"  {resp.agent_name:30s} {resp.score:+.2f}\")\n",
        "    print(f\"\\nFinal: {final_resp.score:+.2f} (Confidence: {final_resp.confidence:.0%})\")\n",
        "    print(f\"Quality: {critique_resp.score:.2f}\")\n",
        "    print(\"\\n✓ TEST COMPLETE!\")\n",
        "\n",
        "# Run it!\n",
        "test_engineer1_engineer3_integration()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9S2jzpDBeY5",
        "outputId": "be973d3d-98bb-40ef-b690-b7890ac785dc"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "INTEGRATION TEST - Engineer 1 + Engineer 3\n",
            "================================================================================\n",
            "\n",
            "[STEP 1] Fetching real data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4032339001.py:120: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df_prices = yf.download(symbol, start=start, end=end, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No news data: {'Information': 'We have detected your API key as BVGUKZR1MHVS0T6B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n",
            "SMA fetch failed: {'Information': 'We have detected your API key as BVGUKZR1MHVS0T6B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n",
            "RSI fetch failed: {'Information': 'We have detected your API key as BVGUKZR1MHVS0T6B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n",
            "✓ Fetched data for AAPL\n",
            "\n",
            "[STEP 2] Preparing data for agents...\n",
            "✓ Data prepared\n",
            "\n",
            "[STEP 3] Testing agents with REAL OpenAI...\n",
            "✓ News: 0.00\n",
            "✓ Earnings: 0.85\n",
            "✓ Market: 0.00\n",
            "✓ Risk: 0.57\n",
            "\n",
            "[STEP 4] Synthesizing recommendation...\n",
            "✓ Final Score: 0.60\n",
            "\n",
            "[STEP 5] Critiquing analysis...\n",
            "✓ Quality: 0.70\n",
            "\n",
            "================================================================================\n",
            "FINAL RESULTS\n",
            "================================================================================\n",
            "\n",
            "Ticker: AAPL\n",
            "\n",
            "Agent Scores:\n",
            "  News Analysis Agent            +0.00\n",
            "  Earnings Analysis Agent        +0.85\n",
            "  Market Signals Agent           +0.00\n",
            "  Risk Assessment Agent          +0.57\n",
            "\n",
            "Final: +0.60 (Confidence: 70%)\n",
            "Quality: 0.70\n",
            "\n",
            "✓ TEST COMPLETE!\n"
          ]
        }
      ]
    }
  ]
}