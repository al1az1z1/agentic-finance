{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## NewsAnalysisAgent\n",
        "This agent reads news headlines about a stock, asks GPT-4 \"are these headlines good or bad news?\", gets back a sentiment score, and packages it in a standardized format for the orchestrator to use.\n",
        "For example: if someone whats get sentiment from new, this agent is  reading news and telling if it's bullish or bearish."
      ],
      "metadata": {
        "id": "GRPVe9rr4sNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EarningsAnalysisAgent\n",
        "The Earnings Analysis Agent examines a company's financial performance (revenue, profits, earnings per share) and determines if the fundamentals are strong by comparing actual results against analyst expectations. It sends this financial data to GPT-4, which returns a score (-1 to +1) indicating whether the company's financials suggest it's a good or weak investment."
      ],
      "metadata": {
        "id": "HTlIGaGI76kf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MarketSignalsAgent\n",
        "The MarketSignalsAgent performs technical analysis by examining stock price patterns, trading volume, and technical indicators (like moving averages, RSI, MACD) to identify trends and momentum. It sends this technical data to GPT-4, which returns a score (-1 to +1) indicating whether the stock's price action suggests a bullish or bearish trend based on chart patterns and trading signals."
      ],
      "metadata": {
        "id": "AhddYSSS8-OH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RiskAssessmentAgent\n",
        "The RiskAssessmentAgent evaluates investment risk by analyzing metrics like beta (volatility), Value at Risk, Sharpe ratio, and sector correlation to determine how risky a stock is for a portfolio. It sends these risk metrics to GPT-4, which returns a risk score (0 to 1, where 0 is low risk and 1 is high risk) along with warnings about potential portfolio concentration or volatility issues."
      ],
      "metadata": {
        "id": "JCEvRRdh8lyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SynthesisAgent\n",
        "The SynthesisAgent acts as the \"decision maker\" that takes all the individual agent analyses (news sentiment, earnings strength, technical signals, risk level) and combines them into a single investment recommendation (STRONG BUY, BUY, HOLD, SELL, STRONG SELL). It sends a summary of all agent scores and findings to GPT-4, which weighs the different perspectives and returns a final actionable recommendation with confidence level and supporting reasoning."
      ],
      "metadata": {
        "id": "ohn9ZLZ0jG0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CritiqueAgent\n",
        "\n",
        "The CritiqueAgent acts as a \"quality control checker\" that reviews the final investment recommendation to catch mistakes, biases, or missing information before presenting it to the user. It examines the SynthesisAgent's recommendation, asks GPT-4 to identify logical flaws or gaps in reasoning, and can adjust the confidence level downward if it finds issues (like  \"didn't consider macroeconomic factors\"), ensuring the final output is reliable and well-reasoned.\n"
      ],
      "metadata": {
        "id": "NjnZdPHAkxys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "AGENT PROCESSING SYSTEM\n",
        "Multi-Agent Financial Analysis\n",
        "\"\"\"\n",
        "\n",
        "from openai import OpenAI\n",
        "from typing import Dict, List, Any, Optional\n",
        "from dataclasses import dataclass, asdict\n",
        "import json\n",
        "from datetime import datetime\n",
        "import os\n",
        "import time\n",
        "import logging\n",
        "\n",
        "# ============================================================================\n",
        "# SETUP API KEYS (Open AI keys before running)\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "\n",
        "# Alpha Vantage\n",
        "os.environ[\"ALPHAVANTAGE_API_KEY\"] = \"BVGUKZR1MHVS0T6B\"\n",
        "\n",
        "# OpenAI - REPLACE WITH YOUR KEY\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-\"  # REPLACE BEFORE RUNNING\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "print(\"API keys configured\")\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "722UdYSysmEh",
        "outputId": "96823d97-e1e6-4f9d-ae91-489fe223ba2d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API keys configured\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# DATA STRUCTURES\n",
        "# ============================================================================\n",
        "\n",
        "@dataclass\n",
        "class AgentResponse:\n",
        "    \"\"\"Standard response format from all agents\"\"\"\n",
        "    agent_name: str\n",
        "    analysis: str\n",
        "    score: float\n",
        "    confidence: float\n",
        "    key_factors: List[str]\n",
        "    timestamp: str\n",
        "    execution_time: float = 0.0  # NEW: Track execution time\n",
        "    token_usage: Optional[Dict[str, int]] = None  # NEW: Track token usage\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class AgentMetrics:\n",
        "    \"\"\"Track agent performance metrics\"\"\"\n",
        "    agent_name: str\n",
        "    total_calls: int = 0\n",
        "    successful_calls: int = 0\n",
        "    failed_calls: int = 0\n",
        "    total_execution_time: float = 0.0\n",
        "    average_execution_time: float = 0.0\n",
        "    total_tokens_used: int = 0\n"
      ],
      "metadata": {
        "id": "HLW4qYK6v58Q"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# SHARED CONTEXT MANAGER\n",
        "# ============================================================================\n",
        "\n",
        "class SharedContext:\n",
        "    \"\"\"Allows agents to share insights with each other\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.context = {}\n",
        "        self.history = []\n",
        "\n",
        "    def add_insight(self, agent_name: str, key: str, value: Any):\n",
        "        \"\"\"Agent shares an insight\"\"\"\n",
        "        self.context[key] = {\n",
        "            'value': value,\n",
        "            'from_agent': agent_name,\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        }\n",
        "        self.history.append({\n",
        "            'agent': agent_name,\n",
        "            'key': key,\n",
        "            'value': value,\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        })\n",
        "        logger.info(f\"{agent_name} shared insight: {key}\")\n",
        "\n",
        "    def get_insight(self, key: str) -> Optional[Any]:\n",
        "        \"\"\"Retrieve an insight\"\"\"\n",
        "        return self.context.get(key, {}).get('value')\n",
        "\n",
        "    def get_all_insights(self) -> Dict:\n",
        "        \"\"\"Get all shared insights\"\"\"\n",
        "        return self.context\n",
        "\n",
        "    def clear(self):\n",
        "        \"\"\"Clear all context\"\"\"\n",
        "        self.context = {}\n",
        "        self.history = []\n",
        "\n",
        "\n",
        "# Initialize shared context for all agents\n",
        "shared_context = SharedContext()\n",
        "\n"
      ],
      "metadata": {
        "id": "vXs8ruokveqN"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# BASE AGENT\n",
        "# ============================================================================\n",
        "\n",
        "class BaseAgent:\n",
        "    \"\"\"Enhanced base class for all financial agents with memory, retry, and metrics\"\"\"\n",
        "\n",
        "    def __init__(self, agent_name: str, model: str = \"gpt-4o-mini\"):\n",
        "        self.agent_name = agent_name\n",
        "        self.model = model\n",
        "        self.memory = []  # Conversation history\n",
        "        self.metrics = AgentMetrics(agent_name=agent_name)  # NEW: Performance metrics\n",
        "        self.shared_context = shared_context  # NEW: Shared context with other agents\n",
        "        logger.info(f\"Initialized {agent_name}\")\n",
        "\n",
        "    def call_llm(self, system_prompt: str, user_message: str, max_retries: int = 3) -> tuple:\n",
        "        \"\"\"\n",
        "        Call LLM with error handling, retry logic, and token tracking\n",
        "        Returns: (response_text, token_usage)\n",
        "        \"\"\"\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                start_time = time.time()\n",
        "\n",
        "                response = client.chat.completions.create(\n",
        "                    model=self.model,\n",
        "                    messages=[\n",
        "                        {\"role\": \"system\", \"content\": system_prompt},\n",
        "                        {\"role\": \"user\", \"content\": user_message}\n",
        "                    ],\n",
        "                    temperature=0.3,\n",
        "                    max_tokens=800\n",
        "                )\n",
        "\n",
        "                elapsed = time.time() - start_time\n",
        "\n",
        "                # Extract token usage\n",
        "                token_usage = {\n",
        "                    'prompt_tokens': response.usage.prompt_tokens,\n",
        "                    'completion_tokens': response.usage.completion_tokens,\n",
        "                    'total_tokens': response.usage.total_tokens\n",
        "                }\n",
        "\n",
        "                # Update metrics\n",
        "                self.metrics.total_tokens_used += token_usage['total_tokens']\n",
        "\n",
        "                logger.info(f\"{self.agent_name} LLM call completed in {elapsed:.2f}s, tokens: {token_usage['total_tokens']}\")\n",
        "\n",
        "                return response.choices[0].message.content, token_usage\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt == max_retries - 1:\n",
        "                    logger.error(f\"{self.agent_name} failed after {max_retries} attempts: {str(e)}\")\n",
        "                    return f\"Error processing request: {str(e)}\", None\n",
        "\n",
        "                wait_time = 2 ** attempt  # Exponential backoff\n",
        "                logger.warning(f\"{self.agent_name} retry {attempt + 1}/{max_retries}, waiting {wait_time}s\")\n",
        "                time.sleep(wait_time)\n",
        "\n",
        "    def add_to_memory(self, interaction: Dict):\n",
        "        \"\"\"Store conversation history\"\"\"\n",
        "        self.memory.append({\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'input': interaction.get('input'),\n",
        "            'output': interaction.get('output'),\n",
        "            'metadata': interaction.get('metadata', {})\n",
        "        })\n",
        "        logger.debug(f\"{self.agent_name} added to memory (total: {len(self.memory)})\")\n",
        "\n",
        "    def get_context(self, last_n: int = 5) -> List[Dict]:\n",
        "        \"\"\"Retrieve recent context from memory\"\"\"\n",
        "        return self.memory[-last_n:] if self.memory else []\n",
        "\n",
        "    def share_insight(self, key: str, value: Any):\n",
        "        \"\"\"Share an insight with other agents via shared context\"\"\"\n",
        "        self.shared_context.add_insight(self.agent_name, key, value)\n",
        "\n",
        "    def get_shared_insights(self) -> Dict:\n",
        "        \"\"\"Get insights shared by other agents\"\"\"\n",
        "        return self.shared_context.get_all_insights()\n",
        "\n",
        "    def update_metrics(self, success: bool, execution_time: float):\n",
        "        \"\"\"Update agent performance metrics\"\"\"\n",
        "        self.metrics.total_calls += 1\n",
        "        if success:\n",
        "            self.metrics.successful_calls += 1\n",
        "        else:\n",
        "            self.metrics.failed_calls += 1\n",
        "\n",
        "        self.metrics.total_execution_time += execution_time\n",
        "        self.metrics.average_execution_time = (\n",
        "            self.metrics.total_execution_time / self.metrics.total_calls\n",
        "        )\n",
        "\n",
        "    def get_metrics(self) -> AgentMetrics:\n",
        "        \"\"\"Get agent performance metrics\"\"\"\n",
        "        return self.metrics\n",
        "\n",
        "    def process(self, data: Dict[str, Any]) -> AgentResponse:\n",
        "        \"\"\"Override in each specialized agent\"\"\"\n",
        "        raise NotImplementedError(\"Each agent must implement process method\")\n"
      ],
      "metadata": {
        "id": "FmbDhBeawKiz"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SPECIALIZED AGENTS\n",
        "# ============================================================================\n",
        "\n",
        "class NewsAnalysisAgent(BaseAgent):\n",
        "    \"\"\"Analyzes financial news sentiment and impact\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(\"News Analysis Agent\")\n",
        "        self.system_prompt = \"\"\"You are a financial news analyst specializing in sentiment analysis.\n",
        "\n",
        "INSTRUCTIONS:\n",
        "1. Analyze news articles objectively\n",
        "2. Consider both positive and negative aspects\n",
        "3. Provide a sentiment score from -1 (very negative) to +1 (very positive)\n",
        "4. Identify key factors driving the sentiment\n",
        "5. Assess potential stock price impact\n",
        "\n",
        "EXAMPLE OUTPUT:\n",
        "{\n",
        "  \"sentiment_score\": 0.75,\n",
        "  \"analysis\": \"Strong positive sentiment driven by earnings beat and product launch\",\n",
        "  \"key_factors\": [\"Earnings exceeded expectations\", \"New product well-received\"],\n",
        "  \"confidence\": 0.85\n",
        "}\n",
        "\n",
        "Return ONLY valid JSON with keys: sentiment_score, analysis, key_factors, confidence\"\"\"\n",
        "\n",
        "    def process(self, data: Dict[str, Any]) -> AgentResponse:\n",
        "        \"\"\"Process news data for sentiment analysis\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            ticker = data.get('ticker', 'AAPL')\n",
        "            news_articles = data.get('news', [])\n",
        "\n",
        "            # Data validation\n",
        "            if not news_articles:\n",
        "                logger.warning(f\"{self.agent_name}: No news data available\")\n",
        "                return AgentResponse(\n",
        "                    agent_name=self.agent_name,\n",
        "                    analysis=\"No news data available for analysis\",\n",
        "                    score=0.0,\n",
        "                    confidence=0.0,\n",
        "                    key_factors=[\"No news data available\"],\n",
        "                    timestamp=datetime.now().isoformat(),\n",
        "                    execution_time=time.time() - start_time\n",
        "                )\n",
        "\n",
        "            # Prepare news summary\n",
        "            news_summary = \"\\n\".join([\n",
        "                f\"- {article.get('title', '')}: {article.get('summary', '')}\"\n",
        "                for article in news_articles[:5]\n",
        "            ])\n",
        "\n",
        "            user_message = f\"\"\"Analyze the following recent news about {ticker}:\n",
        "\n",
        "{news_summary}\n",
        "\n",
        "Provide sentiment analysis and impact assessment.\"\"\"\n",
        "\n",
        "            # Call LLM\n",
        "            llm_response, token_usage = self.call_llm(self.system_prompt, user_message)\n",
        "\n",
        "            # Parse response\n",
        "            try:\n",
        "                result = json.loads(llm_response)\n",
        "                score = result.get('sentiment_score', 0)\n",
        "                analysis = result.get('analysis', llm_response)\n",
        "                key_factors = result.get('key_factors', [])\n",
        "\n",
        "                confidence_raw = result.get('confidence', 0.7)\n",
        "                try:\n",
        "                    confidence = max(0.0, min(1.0, float(confidence_raw)))\n",
        "                except (ValueError, TypeError):\n",
        "                    confidence = 0.7\n",
        "\n",
        "            except json.JSONDecodeError:\n",
        "                logger.warning(f\"{self.agent_name}: Failed to parse JSON response\")\n",
        "                score = 0\n",
        "                analysis = llm_response\n",
        "                key_factors = [\"Unable to parse structured response\"]\n",
        "                confidence = 0.5\n",
        "\n",
        "            execution_time = time.time() - start_time\n",
        "\n",
        "            # Add to memory\n",
        "            self.add_to_memory({\n",
        "                'input': {'ticker': ticker, 'news_count': len(news_articles)},\n",
        "                'output': analysis,\n",
        "                'metadata': {'score': score, 'confidence': confidence}\n",
        "            })\n",
        "\n",
        "            # Share insight with other agents\n",
        "            self.share_insight('news_sentiment', score)\n",
        "            self.share_insight('news_confidence', confidence)\n",
        "\n",
        "            # Update metrics\n",
        "            self.update_metrics(success=True, execution_time=execution_time)\n",
        "\n",
        "            return AgentResponse(\n",
        "                agent_name=self.agent_name,\n",
        "                analysis=analysis,\n",
        "                score=float(score),\n",
        "                confidence=float(confidence),\n",
        "                key_factors=key_factors,\n",
        "                timestamp=datetime.now().isoformat(),\n",
        "                execution_time=execution_time,\n",
        "                token_usage=token_usage\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            execution_time = time.time() - start_time\n",
        "            self.update_metrics(success=False, execution_time=execution_time)\n",
        "            logger.error(f\"{self.agent_name} error: {e}\")\n",
        "            raise"
      ],
      "metadata": {
        "id": "hlk2ZBiawl74"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarningsAnalysisAgent(BaseAgent):\n",
        "    \"\"\"Analyzes earnings reports and financial statements\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(\"Earnings Analysis Agent\")\n",
        "        self.system_prompt = \"\"\"You are a financial analyst specializing in earnings and fundamental analysis.\n",
        "\n",
        "INSTRUCTIONS:\n",
        "1. Analyze company financial metrics objectively\n",
        "2. Compare actuals vs expectations\n",
        "3. Assess fundamental strength from -1 (very weak) to +1 (very strong)\n",
        "4. Identify key financial drivers\n",
        "5. Evaluate growth trends\n",
        "\n",
        "EXAMPLE OUTPUT:\n",
        "{\n",
        "  \"fundamental_score\": 0.80,\n",
        "  \"analysis\": \"Strong fundamentals with revenue and EPS beating expectations\",\n",
        "  \"key_factors\": [\"Revenue beat by 5%\", \"EPS exceeded estimates\", \"Margin expansion\"],\n",
        "  \"confidence\": 0.88\n",
        "}\n",
        "\n",
        "Return ONLY valid JSON with keys: fundamental_score, analysis, key_factors, confidence\"\"\"\n",
        "\n",
        "    def process(self, data: Dict[str, Any]) -> AgentResponse:\n",
        "        \"\"\"Process earnings and financial data\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            ticker = data.get('ticker', 'UNKNOWN')\n",
        "            financials = data.get('financials', {})\n",
        "\n",
        "            # Check for shared insights from other agents\n",
        "            news_sentiment = self.shared_context.get_insight('news_sentiment')\n",
        "            if news_sentiment:\n",
        "                logger.info(f\"{self.agent_name}: Considering news sentiment = {news_sentiment}\")\n",
        "\n",
        "            financial_summary = f\"\"\"\n",
        "Company: {ticker}\n",
        "Revenue: ${financials.get('revenue', 'N/A')}B\n",
        "EPS: ${financials.get('eps', 'N/A')}\n",
        "Revenue Growth: {financials.get('revenue_growth', 'N/A')}%\n",
        "Profit Margin: {financials.get('profit_margin', 'N/A')}%\n",
        "Expected Revenue: ${financials.get('expected_revenue', 'N/A')}B\n",
        "Expected EPS: ${financials.get('expected_eps', 'N/A')}\n",
        "\"\"\"\n",
        "\n",
        "            user_message = f\"\"\"Analyze the following financial data for {ticker}:\n",
        "\n",
        "{financial_summary}\n",
        "\n",
        "Assess fundamental strength and growth prospects.\"\"\"\n",
        "\n",
        "            llm_response, token_usage = self.call_llm(self.system_prompt, user_message)\n",
        "\n",
        "            try:\n",
        "                result = json.loads(llm_response)\n",
        "                score = result.get('fundamental_score', 0)\n",
        "                analysis = result.get('analysis', llm_response)\n",
        "                key_factors = result.get('key_factors', [])\n",
        "\n",
        "                confidence_raw = result.get('confidence', 0.8)\n",
        "                try:\n",
        "                    confidence = max(0.0, min(1.0, float(confidence_raw)))\n",
        "                except (ValueError, TypeError):\n",
        "                    confidence = 0.8\n",
        "\n",
        "            except json.JSONDecodeError:\n",
        "                logger.warning(f\"{self.agent_name}: Failed to parse JSON response\")\n",
        "                score = 0\n",
        "                analysis = llm_response\n",
        "                key_factors = [\"Unable to parse structured response\"]\n",
        "                confidence = 0.6\n",
        "\n",
        "            execution_time = time.time() - start_time\n",
        "\n",
        "            self.add_to_memory({\n",
        "                'input': {'ticker': ticker, 'financials': financials},\n",
        "                'output': analysis,\n",
        "                'metadata': {'score': score, 'confidence': confidence}\n",
        "            })\n",
        "\n",
        "            self.share_insight('fundamental_score', score)\n",
        "            self.share_insight('fundamental_confidence', confidence)\n",
        "\n",
        "            self.update_metrics(success=True, execution_time=execution_time)\n",
        "\n",
        "            return AgentResponse(\n",
        "                agent_name=self.agent_name,\n",
        "                analysis=analysis,\n",
        "                score=float(score),\n",
        "                confidence=float(confidence),\n",
        "                key_factors=key_factors,\n",
        "                timestamp=datetime.now().isoformat(),\n",
        "                execution_time=execution_time,\n",
        "                token_usage=token_usage\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            execution_time = time.time() - start_time\n",
        "            self.update_metrics(success=False, execution_time=execution_time)\n",
        "            logger.error(f\"{self.agent_name} error: {e}\")\n",
        "            raise\n",
        "\n"
      ],
      "metadata": {
        "id": "O1lJHsXAwnPa"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MarketSignalsAgent(BaseAgent):\n",
        "    \"\"\"Performs technical analysis on market data\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(\"Market Signals Agent\")\n",
        "        self.system_prompt = \"\"\"You are a technical analyst specializing in market signals and price patterns.\n",
        "\n",
        "INSTRUCTIONS:\n",
        "1. Analyze technical indicators objectively\n",
        "2. Assess technical strength from -1 (very bearish) to +1 (very bullish)\n",
        "3. Identify support/resistance levels\n",
        "4. Evaluate trend direction and momentum\n",
        "5. Consider volume patterns\n",
        "\n",
        "EXAMPLE OUTPUT:\n",
        "{\n",
        "  \"technical_score\": 0.65,\n",
        "  \"analysis\": \"Bullish technical setup with price above key moving averages\",\n",
        "  \"key_factors\": [\"Price above 50-day MA\", \"RSI indicates strength\", \"Volume confirming uptrend\"],\n",
        "  \"confidence\": 0.75\n",
        "}\n",
        "\n",
        "Return ONLY valid JSON with keys: technical_score, analysis, key_factors, confidence\"\"\"\n",
        "\n",
        "    def process(self, data: Dict[str, Any]) -> AgentResponse:\n",
        "        \"\"\"Process technical market data\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            ticker = data.get('ticker', 'UNKNOWN')\n",
        "            technicals = data.get('technicals', {})\n",
        "\n",
        "            # Validate data\n",
        "            if not technicals.get('current_price') or technicals.get('current_price') == 'N/A':\n",
        "                logger.warning(f\"{self.agent_name}: Insufficient technical data\")\n",
        "                return AgentResponse(\n",
        "                    agent_name=self.agent_name,\n",
        "                    analysis=\"Insufficient technical data for analysis\",\n",
        "                    score=0.0,\n",
        "                    confidence=0.0,\n",
        "                    key_factors=[\"Missing price data\"],\n",
        "                    timestamp=datetime.now().isoformat(),\n",
        "                    execution_time=time.time() - start_time\n",
        "                )\n",
        "\n",
        "            technical_summary = f\"\"\"\n",
        "Ticker: {ticker}\n",
        "Current Price: ${technicals.get('current_price', 'N/A')}\n",
        "50-day MA: ${technicals.get('ma_50', 'N/A')}\n",
        "200-day MA: ${technicals.get('ma_200', 'N/A')}\n",
        "RSI: {technicals.get('rsi', 'N/A')}\n",
        "MACD: {technicals.get('macd', 'N/A')}\n",
        "Volume: {technicals.get('volume', 'N/A')} (Avg: {technicals.get('avg_volume', 'N/A')})\n",
        "Support: ${technicals.get('support', 'N/A')}\n",
        "Resistance: ${technicals.get('resistance', 'N/A')}\n",
        "\"\"\"\n",
        "\n",
        "            user_message = f\"\"\"Analyze the following technical data for {ticker}:\n",
        "\n",
        "{technical_summary}\n",
        "\n",
        "Assess technical strength and price momentum.\"\"\"\n",
        "\n",
        "            llm_response, token_usage = self.call_llm(self.system_prompt, user_message)\n",
        "\n",
        "            try:\n",
        "                result = json.loads(llm_response)\n",
        "                score = result.get('technical_score', 0)\n",
        "                analysis = result.get('analysis', llm_response)\n",
        "                key_factors = result.get('key_factors', [])\n",
        "\n",
        "                confidence_raw = result.get('confidence', 0.7)\n",
        "                try:\n",
        "                    confidence = max(0.0, min(1.0, float(confidence_raw)))\n",
        "                except (ValueError, TypeError):\n",
        "                    confidence = 0.7\n",
        "\n",
        "            except json.JSONDecodeError:\n",
        "                logger.warning(f\"{self.agent_name}: Failed to parse JSON response\")\n",
        "                score = 0\n",
        "                analysis = llm_response\n",
        "                key_factors = [\"Unable to parse structured response\"]\n",
        "                confidence = 0.5\n",
        "\n",
        "            execution_time = time.time() - start_time\n",
        "\n",
        "            self.add_to_memory({\n",
        "                'input': {'ticker': ticker, 'technicals': technicals},\n",
        "                'output': analysis,\n",
        "                'metadata': {'score': score, 'confidence': confidence}\n",
        "            })\n",
        "\n",
        "            self.share_insight('technical_score', score)\n",
        "            self.share_insight('technical_confidence', confidence)\n",
        "\n",
        "            self.update_metrics(success=True, execution_time=execution_time)\n",
        "\n",
        "            return AgentResponse(\n",
        "                agent_name=self.agent_name,\n",
        "                analysis=analysis,\n",
        "                score=float(score),\n",
        "                confidence=float(confidence),\n",
        "                key_factors=key_factors,\n",
        "                timestamp=datetime.now().isoformat(),\n",
        "                execution_time=execution_time,\n",
        "                token_usage=token_usage\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            execution_time = time.time() - start_time\n",
        "            self.update_metrics(success=False, execution_time=execution_time)\n",
        "            logger.error(f\"{self.agent_name} error: {e}\")\n",
        "            raise"
      ],
      "metadata": {
        "id": "IkhL7zL7xHmY"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RiskAssessmentAgent(BaseAgent):\n",
        "    \"\"\"Assesses investment risk and portfolio fit\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(\"Risk Assessment Agent\")\n",
        "        self.system_prompt = \"\"\"You are a risk management analyst specializing in portfolio risk assessment.\n",
        "\n",
        "INSTRUCTIONS:\n",
        "1. Analyze risk metrics objectively\n",
        "2. Provide risk level score from 0 (very low risk) to 1 (very high risk)\n",
        "3. Identify key risk factors\n",
        "4. Assess portfolio diversification implications\n",
        "5. Evaluate risk-adjusted returns\n",
        "\n",
        "EXAMPLE OUTPUT:\n",
        "{\n",
        "  \"risk_score\": 0.45,\n",
        "  \"analysis\": \"Moderate risk profile with acceptable volatility and strong Sharpe ratio\",\n",
        "  \"key_factors\": [\"Beta of 1.15 indicates moderate volatility\", \"Strong Sharpe ratio\", \"Manageable drawdown\"],\n",
        "  \"confidence\": 0.82\n",
        "}\n",
        "\n",
        "Return ONLY valid JSON with keys: risk_score, analysis, key_factors, confidence\"\"\"\n",
        "\n",
        "    def process(self, data: Dict[str, Any]) -> AgentResponse:\n",
        "        \"\"\"Process risk metrics\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            ticker = data.get('ticker', 'UNKNOWN')\n",
        "            risk_data = data.get('risk_metrics', {})\n",
        "\n",
        "            risk_summary = f\"\"\"\n",
        "Ticker: {ticker}\n",
        "Beta: {risk_data.get('beta', 'N/A')}\n",
        "Volatility (30-day): {risk_data.get('volatility', 'N/A')}%\n",
        "Value at Risk (5%): ${risk_data.get('var_5', 'N/A')}\n",
        "Sharpe Ratio: {risk_data.get('sharpe_ratio', 'N/A')}\n",
        "Max Drawdown: {risk_data.get('max_drawdown', 'N/A')}%\n",
        "Sector Correlation: {risk_data.get('sector_correlation', 'N/A')}\n",
        "P/E Ratio: {risk_data.get('pe_ratio', 'N/A')}\n",
        "\"\"\"\n",
        "\n",
        "            user_message = f\"\"\"Analyze the following risk metrics for {ticker}:\n",
        "\n",
        "{risk_summary}\n",
        "\n",
        "Assess overall investment risk and portfolio implications.\"\"\"\n",
        "\n",
        "            llm_response, token_usage = self.call_llm(self.system_prompt, user_message)\n",
        "\n",
        "            try:\n",
        "                result = json.loads(llm_response)\n",
        "                score = result.get('risk_score', 0.5)\n",
        "                analysis = result.get('analysis', llm_response)\n",
        "                key_factors = result.get('key_factors', [])\n",
        "\n",
        "                confidence_raw = result.get('confidence', 0.8)\n",
        "                try:\n",
        "                    confidence = max(0.0, min(1.0, float(confidence_raw)))\n",
        "                except (ValueError, TypeError):\n",
        "                    confidence = 0.8\n",
        "\n",
        "            except json.JSONDecodeError:\n",
        "                logger.warning(f\"{self.agent_name}: Failed to parse JSON response\")\n",
        "                score = 0.5\n",
        "                analysis = llm_response\n",
        "                key_factors = [\"Unable to parse structured response\"]\n",
        "                confidence = 0.6\n",
        "\n",
        "            execution_time = time.time() - start_time\n",
        "\n",
        "            self.add_to_memory({\n",
        "                'input': {'ticker': ticker, 'risk_metrics': risk_data},\n",
        "                'output': analysis,\n",
        "                'metadata': {'score': score, 'confidence': confidence}\n",
        "            })\n",
        "\n",
        "            self.share_insight('risk_score', score)\n",
        "            self.share_insight('risk_confidence', confidence)\n",
        "\n",
        "            self.update_metrics(success=True, execution_time=execution_time)\n",
        "\n",
        "            return AgentResponse(\n",
        "                agent_name=self.agent_name,\n",
        "                analysis=analysis,\n",
        "                score=float(score),\n",
        "                confidence=float(confidence),\n",
        "                key_factors=key_factors,\n",
        "                timestamp=datetime.now().isoformat(),\n",
        "                execution_time=execution_time,\n",
        "                token_usage=token_usage\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            execution_time = time.time() - start_time\n",
        "            self.update_metrics(success=False, execution_time=execution_time)\n",
        "            logger.error(f\"{self.agent_name} error: {e}\")\n",
        "            raise\n",
        "\n"
      ],
      "metadata": {
        "id": "cmzoIPtGxJ6G"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SynthesisAgent(BaseAgent):\n",
        "    \"\"\"Combines insights from all agents into final recommendation\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(\"Research Synthesis Agent\")\n",
        "        self.system_prompt = \"\"\"You are a senior investment analyst who synthesizes multiple analyses into actionable recommendations.\n",
        "\n",
        "INSTRUCTIONS:\n",
        "1. Review all agent analyses objectively\n",
        "2. Weigh different factors appropriately\n",
        "3. Provide clear investment recommendation (STRONG BUY, BUY, HOLD, SELL, STRONG SELL)\n",
        "4. State confidence level (0 to 1)\n",
        "5. Summarize key reasoning\n",
        "6. Note important risks\n",
        "\n",
        "EXAMPLE OUTPUT:\n",
        "{\n",
        "  \"recommendation\": \"BUY\",\n",
        "  \"confidence\": 0.78,\n",
        "  \"analysis\": \"Strong fundamentals and positive technical signals support a buy recommendation despite moderate risk\",\n",
        "  \"key_points\": [\"Earnings beat expectations\", \"Technical breakout\", \"Acceptable risk profile\"],\n",
        "  \"risks\": [\"Market volatility\", \"Sector headwinds\"]\n",
        "}\n",
        "\n",
        "Return ONLY valid JSON with keys: recommendation, confidence, analysis, key_points, risks\"\"\"\n",
        "\n",
        "    def process(self, agent_responses: List[AgentResponse]) -> AgentResponse:\n",
        "        \"\"\"Synthesize all agent responses\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            # Check shared insights\n",
        "            all_insights = self.get_shared_insights()\n",
        "            logger.info(f\"{self.agent_name}: Reviewing {len(all_insights)} shared insights\")\n",
        "\n",
        "            analyses_summary = \"\\n\\n\".join([\n",
        "                f\"{resp.agent_name}:\\n\"\n",
        "                f\"Score: {resp.score}\\n\"\n",
        "                f\"Confidence: {resp.confidence}\\n\"\n",
        "                f\"Analysis: {resp.analysis}\\n\"\n",
        "                f\"Key Factors: {', '.join(resp.key_factors)}\"\n",
        "                for resp in agent_responses\n",
        "            ])\n",
        "\n",
        "            user_message = f\"\"\"Synthesize the following analyses into a final investment recommendation:\n",
        "\n",
        "{analyses_summary}\n",
        "\n",
        "Provide comprehensive investment recommendation with supporting reasoning.\"\"\"\n",
        "\n",
        "            llm_response, token_usage = self.call_llm(self.system_prompt, user_message)\n",
        "\n",
        "            try:\n",
        "                result = json.loads(llm_response)\n",
        "                recommendation = result.get('recommendation', 'HOLD')\n",
        "                analysis = result.get('analysis', llm_response)\n",
        "                key_factors = result.get('key_points', [])\n",
        "\n",
        "                confidence_raw = result.get('confidence', 0.7)\n",
        "                try:\n",
        "                    confidence = max(0.0, min(1.0, float(confidence_raw)))\n",
        "                except (ValueError, TypeError):\n",
        "                    confidence = 0.7\n",
        "\n",
        "                rec_to_score = {\n",
        "                    'STRONG BUY': 1.0,\n",
        "                    'BUY': 0.6,\n",
        "                    'HOLD': 0.0,\n",
        "                    'SELL': -0.6,\n",
        "                    'STRONG SELL': -1.0\n",
        "                }\n",
        "                score = rec_to_score.get(recommendation, 0.0)\n",
        "\n",
        "            except json.JSONDecodeError:\n",
        "                logger.warning(f\"{self.agent_name}: Failed to parse JSON response\")\n",
        "                score = 0\n",
        "                analysis = llm_response\n",
        "                key_factors = [\"Unable to parse structured response\"]\n",
        "                confidence = 0.6\n",
        "\n",
        "            execution_time = time.time() - start_time\n",
        "\n",
        "            self.add_to_memory({\n",
        "                'input': {'num_agents': len(agent_responses)},\n",
        "                'output': analysis,\n",
        "                'metadata': {'recommendation': recommendation, 'confidence': confidence}\n",
        "            })\n",
        "\n",
        "            self.share_insight('final_recommendation', recommendation)\n",
        "            self.share_insight('final_score', score)\n",
        "\n",
        "            self.update_metrics(success=True, execution_time=execution_time)\n",
        "\n",
        "            return AgentResponse(\n",
        "                agent_name=self.agent_name,\n",
        "                analysis=analysis,\n",
        "                score=float(score),\n",
        "                confidence=float(confidence),\n",
        "                key_factors=key_factors,\n",
        "                timestamp=datetime.now().isoformat(),\n",
        "                execution_time=execution_time,\n",
        "                token_usage=token_usage\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            execution_time = time.time() - start_time\n",
        "            self.update_metrics(success=False, execution_time=execution_time)\n",
        "            logger.error(f\"{self.agent_name} error: {e}\")\n",
        "            raise\n"
      ],
      "metadata": {
        "id": "rm3w15nWxYqT"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CritiqueAgent(BaseAgent):\n",
        "    \"\"\"Reviews and validates analysis quality\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(\"Critique & Validation Agent\")\n",
        "        self.system_prompt = \"\"\"You are a critique analyst who reviews investment recommendations for biases, logical errors, and completeness.\n",
        "\n",
        "INSTRUCTIONS:\n",
        "1. Review the synthesis objectively\n",
        "2. Identify logical inconsistencies\n",
        "3. Detect potential biases\n",
        "4. Note missing considerations\n",
        "5. Assess data quality\n",
        "6. Recommend confidence adjustments\n",
        "\n",
        "EXAMPLE OUTPUT:\n",
        "{\n",
        "  \"quality_score\": 0.82,\n",
        "  \"issues_found\": [\"Limited macroeconomic analysis\"],\n",
        "  \"suggestions\": [\"Consider Federal Reserve policy impact\", \"Add sector comparison\"],\n",
        "  \"adjusted_confidence\": 0.75\n",
        "}\n",
        "\n",
        "Return ONLY valid JSON with keys: quality_score, issues_found, suggestions, adjusted_confidence\"\"\"\n",
        "\n",
        "    def process(self, synthesis_response: AgentResponse) -> AgentResponse:\n",
        "        \"\"\"Critique the synthesis\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            user_message = f\"\"\"Review this investment analysis for quality and completeness:\n",
        "\n",
        "Recommendation: {synthesis_response.analysis}\n",
        "Confidence: {synthesis_response.confidence}\n",
        "Key Factors: {', '.join(synthesis_response.key_factors)}\n",
        "\n",
        "Identify any issues, biases, or missing elements.\"\"\"\n",
        "\n",
        "            llm_response, token_usage = self.call_llm(self.system_prompt, user_message)\n",
        "\n",
        "            try:\n",
        "                result = json.loads(llm_response)\n",
        "                quality_score = result.get('quality_score', 0.7)\n",
        "                issues = result.get('issues_found', [])\n",
        "                suggestions = result.get('suggestions', [])\n",
        "                adjusted_confidence_raw = result.get('adjusted_confidence', synthesis_response.confidence)\n",
        "\n",
        "                try:\n",
        "                    adjusted_confidence = max(0.0, min(1.0, float(adjusted_confidence_raw)))\n",
        "                except (ValueError, TypeError):\n",
        "                    adjusted_confidence = synthesis_response.confidence\n",
        "\n",
        "                analysis = f\"Quality Score: {quality_score}\\n\"\n",
        "                if issues:\n",
        "                    analysis += f\"Issues Found: {', '.join(issues)}\\n\"\n",
        "                if suggestions:\n",
        "                    analysis += f\"Suggestions: {', '.join(suggestions)}\"\n",
        "\n",
        "                key_factors = issues if issues else [\"No major issues found\"]\n",
        "\n",
        "            except json.JSONDecodeError:\n",
        "                logger.warning(f\"{self.agent_name}: Failed to parse JSON response\")\n",
        "                quality_score = 0.7\n",
        "                analysis = llm_response\n",
        "                adjusted_confidence = synthesis_response.confidence\n",
        "                key_factors = [\"Unable to parse structured response\"]\n",
        "\n",
        "            execution_time = time.time() - start_time\n",
        "\n",
        "            self.add_to_memory({\n",
        "                'input': {'synthesis_confidence': synthesis_response.confidence},\n",
        "                'output': analysis,\n",
        "                'metadata': {'quality_score': quality_score, 'adjusted_confidence': adjusted_confidence}\n",
        "            })\n",
        "\n",
        "            self.share_insight('quality_score', quality_score)\n",
        "            self.share_insight('adjusted_confidence', adjusted_confidence)\n",
        "\n",
        "            self.update_metrics(success=True, execution_time=execution_time)\n",
        "\n",
        "            return AgentResponse(\n",
        "                agent_name=self.agent_name,\n",
        "                analysis=analysis,\n",
        "                score=float(quality_score),\n",
        "                confidence=float(adjusted_confidence),\n",
        "                key_factors=key_factors,\n",
        "                timestamp=datetime.now().isoformat(),\n",
        "                execution_time=execution_time,\n",
        "                token_usage=token_usage\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            execution_time = time.time() - start_time\n",
        "            self.update_metrics(success=False, execution_time=execution_time)\n",
        "            logger.error(f\"{self.agent_name} error: {e}\")\n",
        "            raise"
      ],
      "metadata": {
        "id": "FRwtWWV-xqyu"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# UTILITY FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def print_agent_metrics():\n",
        "    \"\"\"Print performance metrics for all agents\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"AGENT PERFORMANCE METRICS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    agents = [\n",
        "        NewsAnalysisAgent(),\n",
        "        EarningsAnalysisAgent(),\n",
        "        MarketSignalsAgent(),\n",
        "        RiskAssessmentAgent(),\n",
        "        SynthesisAgent(),\n",
        "        CritiqueAgent()\n",
        "    ]\n",
        "\n",
        "    for agent in agents:\n",
        "        metrics = agent.get_metrics()\n",
        "        print(f\"\\n{metrics.agent_name}:\")\n",
        "        print(f\"  Total Calls: {metrics.total_calls}\")\n",
        "        print(f\"  Success Rate: {metrics.successful_calls}/{metrics.total_calls}\")\n",
        "        print(f\"  Avg Execution Time: {metrics.average_execution_time:.2f}s\")\n",
        "        print(f\"  Total Tokens Used: {metrics.total_tokens_used}\")\n",
        "\n",
        "\n",
        "def print_shared_insights():\n",
        "    \"\"\"Print all shared insights between agents\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SHARED INSIGHTS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    insights = shared_context.get_all_insights()\n",
        "    for key, data in insights.items():\n",
        "        print(f\"\\n{key}: {data['value']}\")\n",
        "        print(f\"  From: {data['from_agent']}\")\n",
        "        print(f\"  Time: {data['timestamp']}\")"
      ],
      "metadata": {
        "id": "PwVXOoCOx3s7"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"notebooks/01_data_ingestion.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1J_syHGmJHhA8XcAtxw7nQ0KPWMJbnSkd\n",
        "\"\"\"\n",
        "\n",
        "#import os\n",
        "os.environ[\"ALPHAVANTAGE_API_KEY\"] = \"BVGUKZR1MHVS0T6B\"\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from datasets import Dataset\n",
        "\n",
        "# ------------------------------\n",
        "# Helper: Convert Pandas  Hugging Face Dataset\n",
        "# ------------------------------\n",
        "def to_hf(df, schema=None):\n",
        "    \"\"\"Convert a pandas DataFrame to a Hugging Face Dataset. Handles empty gracefully.\"\"\"\n",
        "    if df is None or getattr(df, \"empty\", True):\n",
        "        if schema:\n",
        "            return Dataset.from_dict({c: [] for c in schema})\n",
        "        return Dataset.from_dict({})\n",
        "    if schema:\n",
        "        df = df[[c for c in schema if c in df.columns]].copy()\n",
        "    return Dataset.from_pandas(df.reset_index(drop=True), preserve_index=False)\n",
        "\n",
        "# ------------------------------\n",
        "# Alpha Vantage Connector (for news + indicators only)\n",
        "# ------------------------------\n",
        "class AlphaConnector:\n",
        "    def __init__(self, api_key=None):\n",
        "        # Pick up API key from os.environ if not passed directly\n",
        "        self.api_key = api_key or os.getenv(\"ALPHAVANTAGE_API_KEY\")\n",
        "        if not self.api_key:\n",
        "            raise ValueError(\"Alpha Vantage API key not found. Set os.environ['ALPHAVANTAGE_API_KEY'].\")\n",
        "\n",
        "        self.base_url = \"https://www.alphavantage.co/query\"\n",
        "\n",
        "    def fetch_news(self, symbol):\n",
        "        \"\"\"Fetch company news & sentiment (Alpha Vantage).\"\"\"\n",
        "        params = {\n",
        "            \"function\": \"NEWS_SENTIMENT\",\n",
        "            \"tickers\": symbol,\n",
        "            \"apikey\": self.api_key\n",
        "        }\n",
        "        r = requests.get(self.base_url, params=params)\n",
        "        data = r.json()\n",
        "\n",
        "        if \"feed\" not in data:\n",
        "            print(\"No news data:\", data)\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        rows = []\n",
        "        for item in data[\"feed\"]:\n",
        "            rows.append({\n",
        "                \"published_at\": item.get(\"time_published\"),\n",
        "                \"source\": item.get(\"source\"),\n",
        "                \"title\": item.get(\"title\"),\n",
        "                \"summary\": item.get(\"summary\"),\n",
        "                \"url\": item.get(\"url\"),\n",
        "                \"overall_sentiment\": item.get(\"overall_sentiment_label\"),\n",
        "                # ** Added By Ali **\n",
        "                \"overall_sentiment_score\": item.get(\"overall_sentiment_score\") # both label and score so later agents (NewsAnalysisAgent, SynthesisAgent, etc.) can use either\n",
        "            })\n",
        "        return pd.DataFrame(rows)\n",
        "\n",
        "    def fetch_indicator(self, symbol, indicator, interval=\"daily\", time_period=14, series_type=\"close\"):\n",
        "        \"\"\"Generic technical indicator fetch (SMA, RSI, MACD).\"\"\"\n",
        "        params = {\n",
        "            \"function\": indicator,\n",
        "            \"symbol\": symbol,\n",
        "            \"interval\": interval,\n",
        "            \"time_period\": time_period,\n",
        "            \"series_type\": series_type,\n",
        "            \"apikey\": self.api_key\n",
        "        }\n",
        "        r = requests.get(self.base_url, params=params)\n",
        "        data = r.json()\n",
        "\n",
        "        key_map = {\n",
        "            \"SMA\": \"Technical Analysis: SMA\",\n",
        "            \"RSI\": \"Technical Analysis: RSI\",\n",
        "            \"MACD\": \"Technical Analysis: MACD\"\n",
        "        }\n",
        "        key = key_map.get(indicator)\n",
        "        if key not in data:\n",
        "            print(f\"{indicator} fetch failed:\", data)\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        df = pd.DataFrame.from_dict(data[key], orient=\"index\")\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        df.reset_index(inplace=True)\n",
        "        df = df.rename(columns={\"index\": \"date\"})\n",
        "\n",
        "        # Cast numeric values\n",
        "        for col in df.columns:\n",
        "            if col != \"date\":\n",
        "                df[col] = df[col].astype(float)\n",
        "\n",
        "        return df\n",
        "\n",
        "# ------------------------------\n",
        "# Data Ingestion Manager\n",
        "# ------------------------------\n",
        "class DataIngestionManager:\n",
        "    def __init__(self, api_key=None):\n",
        "        self.alpha = AlphaConnector(api_key)\n",
        "\n",
        "    def fetch_all(self, symbol, start=None, end=None):\n",
        "        \"\"\"Fetch prices (Yahoo), news (Alpha Vantage), SMA, RSI (Alpha Vantage).\"\"\"\n",
        "        datasets = {}\n",
        "\n",
        "        # Prices from Yahoo Finance (unlimited)\n",
        "        try:\n",
        "            df_prices = yf.download(symbol, start=start, end=end, progress=False)\n",
        "\n",
        "            # Flatten MultiIndex columns if necessary\n",
        "            if isinstance(df_prices.columns, pd.MultiIndex):\n",
        "                df_prices.columns = [c[0].lower() for c in df_prices.columns]\n",
        "\n",
        "            df_prices = df_prices.reset_index().rename(columns={\n",
        "                \"Date\": \"date\",\n",
        "                \"open\": \"open\",\n",
        "                \"high\": \"high\",\n",
        "                \"low\": \"low\",\n",
        "                \"close\": \"close\",\n",
        "                \"adj close\": \"adj_close\",\n",
        "                \"volume\": \"volume\"\n",
        "            })\n",
        "            df_prices[\"date\"] = df_prices[\"date\"].astype(str)\n",
        "\n",
        "            datasets[\"prices\"] = to_hf(\n",
        "                df_prices, schema=[\"date\",\"open\",\"high\",\"low\",\"close\",\"adj_close\",\"volume\"]\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(\"Yahoo Finance fetch failed:\", e)\n",
        "            datasets[\"prices\"] = to_hf(pd.DataFrame(), schema=[\"date\",\"open\",\"high\",\"low\",\"close\",\"adj_close\",\"volume\"])\n",
        "\n",
        "        # News from Alpha Vantage\n",
        "        datasets[\"news\"] = to_hf(\n",
        "            self.alpha.fetch_news(symbol),\n",
        "            schema=[\"published_at\",\"source\",\"title\",\"summary\",\"url\",\"overall_sentiment\"]\n",
        "        )\n",
        "\n",
        "        # Technical Indicators from Alpha Vantage\n",
        "        datasets[\"sma\"] = to_hf(\n",
        "            self.alpha.fetch_indicator(symbol, \"SMA\", time_period=20),\n",
        "            schema=[\"date\",\"SMA\"]\n",
        "        )\n",
        "        datasets[\"rsi\"] = to_hf(\n",
        "            self.alpha.fetch_indicator(symbol, \"RSI\", time_period=14),\n",
        "            schema=[\"date\",\"RSI\"]\n",
        "        )\n",
        "\n",
        "        # Removed MACD to avoid premium-only error\n",
        "        return datasets\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "mgr = DataIngestionManager()  # will pick up the key from os.environ\n",
        "symbol = \"AAPL\"\n",
        "start = (datetime.now() - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
        "end   = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "datasets = mgr.fetch_all(symbol, start, end)\n",
        "\n",
        "print(\"Prices sample:\")\n",
        "print(datasets[\"prices\"].to_pandas().head())\n",
        "\n",
        "print(\"News sample:\")\n",
        "print(datasets[\"news\"].to_pandas().head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvXsw-Yb3VUn",
        "outputId": "2aacb3d9-74c0-4265-80b7-546a2c062c45"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4032339001.py:120: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df_prices = yf.download(symbol, start=start, end=end, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No news data: {'Information': 'We have detected your API key as BVGUKZR1MHVS0T6B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n",
            "SMA fetch failed: {'Information': 'We have detected your API key as BVGUKZR1MHVS0T6B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n",
            "RSI fetch failed: {'Information': 'We have detected your API key as BVGUKZR1MHVS0T6B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n",
            "Prices sample:\n",
            "         date        open        high         low       close     volume\n",
            "0  2025-09-18  239.970001  241.199997  236.649994  237.880005   44249600\n",
            "1  2025-09-19  241.229996  246.300003  240.210007  245.500000  163741300\n",
            "2  2025-09-22  248.300003  256.640015  248.119995  256.079987  105517400\n",
            "3  2025-09-23  255.880005  257.339996  253.580002  254.429993   60275200\n",
            "4  2025-09-24  255.220001  255.740005  251.039993  252.309998   42303700\n",
            "News sample:\n",
            "Empty DataFrame\n",
            "Columns: [published_at, source, title, summary, url, overall_sentiment]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# INTEGRATION TEST CELL - Engineer 1 + Engineer 3\n",
        "# ============================================================================\n",
        "\n",
        "def test_engineer1_engineer3():\n",
        "    \"\"\"Test  Engineer 1 and Engineer 3 code\"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"INTEGRATION TEST - Engineer 1 + Engineer 3\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    from datetime import datetime, timedelta\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 1: Fetch data\n",
        "    # ========================================================================\n",
        "\n",
        "    print(\"\\n[STEP 1] Fetching data ...\")\n",
        "\n",
        "    mgr = DataIngestionManager()\n",
        "    symbol = \"AAPL\"\n",
        "    start = (datetime.now() - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
        "    end = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    datasets = mgr.fetch_all(symbol, start, end)\n",
        "\n",
        "    # Convert to pandas\n",
        "    prices_df = datasets[\"prices\"].to_pandas()\n",
        "    news_df = datasets[\"news\"].to_pandas()\n",
        "    sma_df = datasets[\"sma\"].to_pandas()\n",
        "    rsi_df = datasets[\"rsi\"].to_pandas()\n",
        "\n",
        "    print(f\"Fetched data for {symbol}\")\n",
        "    print(f\"  Prices: {len(prices_df)} rows\")\n",
        "    print(f\"  News: {len(news_df)} articles\")\n",
        "    print(f\"  SMA: {len(sma_df)} points\")\n",
        "    print(f\"  RSI: {len(rsi_df)} points\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 2: Prepare inputs for agents\n",
        "    # ========================================================================\n",
        "\n",
        "    print(\"\\n[STEP 2] Preparing data for agents...\")\n",
        "\n",
        "    # News input\n",
        "    news_articles = news_df.head(5).to_dict('records') if len(news_df) > 0 else []\n",
        "    news_input = {'ticker': symbol, 'news': news_articles}\n",
        "\n",
        "    # Technical input\n",
        "    latest_price = prices_df.iloc[-1] if len(prices_df) > 0 else {}\n",
        "    latest_sma = sma_df.iloc[-1] if len(sma_df) > 0 else {}\n",
        "    latest_rsi = rsi_df.iloc[-1] if len(rsi_df) > 0 else {}\n",
        "\n",
        "    technicals_input = {\n",
        "        'ticker': symbol,\n",
        "        'technicals': {\n",
        "            'current_price': str(latest_price.get('close', 'N/A')),\n",
        "            'ma_50': str(latest_sma.get('SMA', 'N/A')),\n",
        "            'rsi': str(latest_rsi.get('RSI', 'N/A')),\n",
        "            'volume': str(latest_price.get('volume', 'N/A'))\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Financial input (mock data)\n",
        "    financials_input = {\n",
        "        'ticker': symbol,\n",
        "        'financials': {\n",
        "            'revenue': '394.3',\n",
        "            'eps': '6.42',\n",
        "            'revenue_growth': '15.0',\n",
        "            'profit_margin': '26.3'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Risk input (mock data)\n",
        "    risk_input = {\n",
        "        'ticker': symbol,\n",
        "        'risk_metrics': {\n",
        "            'beta': '1.15',\n",
        "            'volatility': '22.5',\n",
        "            'sharpe_ratio': '1.35'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(\"Data prepared for all agents\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 3: Run with agents\n",
        "    # ========================================================================\n",
        "\n",
        "    print(\"\\n[STEP 3] Running Engineer 3 agents...\")\n",
        "\n",
        "    # Agent 1: News\n",
        "    news_agent = NewsAnalysisAgent()\n",
        "    news_resp = news_agent.process(news_input)\n",
        "    print(f\"  News Analysis: {news_resp.score:+.2f} (confidence: {news_resp.confidence:.0%})\")\n",
        "\n",
        "    # Agent 2: Earnings\n",
        "    earnings_agent = EarningsAnalysisAgent()\n",
        "    earn_resp = earnings_agent.process(financials_input)\n",
        "    print(f\"  Earnings Analysis: {earn_resp.score:+.2f} (confidence: {earn_resp.confidence:.0%})\")\n",
        "\n",
        "    # Agent 3: Technical\n",
        "    market_agent = MarketSignalsAgent()\n",
        "    market_resp = market_agent.process(technicals_input)\n",
        "    print(f\"  Technical Analysis: {market_resp.score:+.2f} (confidence: {market_resp.confidence:.0%})\")\n",
        "\n",
        "    # Agent 4: Risk\n",
        "    risk_agent = RiskAssessmentAgent()\n",
        "    risk_resp = risk_agent.process(risk_input)\n",
        "    print(f\"  Risk Assessment: {risk_resp.score:.2f} (confidence: {risk_resp.confidence:.0%})\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 4: Synthesize with synthesis agent\n",
        "    # ========================================================================\n",
        "\n",
        "    print(\"\\n[STEP 4] Synthesizing recommendation...\")\n",
        "\n",
        "    all_responses = [news_resp, earn_resp, market_resp, risk_resp]\n",
        "    synthesis_agent = SynthesisAgent()\n",
        "    final_resp = synthesis_agent.process(all_responses)\n",
        "    print(f\"  Synthesis Score: {final_resp.score:+.2f} (confidence: {final_resp.confidence:.0%})\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 5: Critique with critique agent\n",
        "    # ========================================================================\n",
        "\n",
        "    print(\"\\n[STEP 5] Critiquing analysis...\")\n",
        "\n",
        "    critique_agent = CritiqueAgent()\n",
        "    critique_resp = critique_agent.process(final_resp)\n",
        "    print(f\"  Quality Score: {critique_resp.score:.2f}\")\n",
        "    print(f\"  Adjusted Confidence: {critique_resp.confidence:.0%}\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # FINAL RESULTS\n",
        "    # ========================================================================\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"FINAL RESULTS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(f\"\\nStock: {symbol}\")\n",
        "    print(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "    print(f\"\\nAgent Scores:\")\n",
        "    for resp in all_responses:\n",
        "        print(f\"  {resp.agent_name:30s} {resp.score:+.2f}\")\n",
        "\n",
        "    # Determine recommendation\n",
        "    score = final_resp.score\n",
        "    if score >= 0.6:\n",
        "        rec = \"STRONG BUY\" if score >= 0.8 else \"BUY\"\n",
        "    elif score <= -0.6:\n",
        "        rec = \"STRONG SELL\" if score <= -0.8 else \"SELL\"\n",
        "    else:\n",
        "        rec = \"HOLD\"\n",
        "\n",
        "    print(f\"\\nFinal Recommendation: {rec}\")\n",
        "    print(f\"   Score: {final_resp.score:+.2f}\")\n",
        "    print(f\"   Confidence: {final_resp.confidence:.0%}\")\n",
        "    print(f\"   Quality: {critique_resp.score:.2f}/1.0\")\n",
        "\n",
        "    print(f\"\\nAnalysis:\")\n",
        "    print(f\"   {final_resp.analysis[:200]}...\")\n",
        "\n",
        "    print(f\"\\nKey Factors:\")\n",
        "    for i, factor in enumerate(final_resp.key_factors[:3], 1):\n",
        "        print(f\"   {i}. {factor}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\" TEST COMPLETE!\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return {\n",
        "        'symbol': symbol,\n",
        "        'recommendation': rec,\n",
        "        'score': final_resp.score,\n",
        "        'confidence': final_resp.confidence,\n",
        "        'quality': critique_resp.score,\n",
        "        'all_responses': all_responses,\n",
        "        'synthesis': final_resp,\n",
        "        'critique': critique_resp\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# RUN THE TEST\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nStarting Integration Test...\\n\")\n",
        "\n",
        "result = test_engineer1_engineer3()\n",
        "\n",
        "if result:\n",
        "    print(f\"\\nSUCCESS! integration works! \")\n",
        "    print(f\"\\nQuick Summary:\")\n",
        "    print(f\"   Recommendation: {result['recommendation']}\")\n",
        "    print(f\"   Final Score: {result['score']:+.2f}\")\n",
        "    print(f\"   Confidence: {result['confidence']:.0%}\")\n",
        "    print(f\"   Quality: {result['quality']:.2f}/1.0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3wpQoAHtwmV",
        "outputId": "f9c7517b-a67d-40bf-d8ff-3fbb21851fb6"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Integration Test...\n",
            "\n",
            "================================================================================\n",
            "INTEGRATION TEST - Engineer 1 + Engineer 3\n",
            "================================================================================\n",
            "\n",
            "[STEP 1] Fetching data ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4032339001.py:120: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df_prices = yf.download(symbol, start=start, end=end, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No news data: {'Information': 'We have detected your API key as BVGUKZR1MHVS0T6B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n",
            "SMA fetch failed: {'Information': 'We have detected your API key as BVGUKZR1MHVS0T6B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:News Analysis Agent: No news data available\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RSI fetch failed: {'Information': 'We have detected your API key as BVGUKZR1MHVS0T6B and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n",
            "Fetched data for AAPL\n",
            "  Prices: 22 rows\n",
            "  News: 0 articles\n",
            "  SMA: 0 points\n",
            "  RSI: 0 points\n",
            "\n",
            "[STEP 2] Preparing data for agents...\n",
            "Data prepared for all agents\n",
            "\n",
            "[STEP 3] Running Engineer 3 agents...\n",
            "  News Analysis: +0.00 (confidence: 0%)\n",
            "  Earnings Analysis: +0.85 (confidence: 80%)\n",
            "  Technical Analysis: -1.00 (confidence: 10%)\n",
            "  Risk Assessment: 0.40 (confidence: 75%)\n",
            "\n",
            "[STEP 4] Synthesizing recommendation...\n",
            "  Synthesis Score: +0.00 (confidence: 65%)\n",
            "\n",
            "[STEP 5] Critiquing analysis...\n",
            "  Quality Score: 0.60\n",
            "  Adjusted Confidence: 50%\n",
            "\n",
            "================================================================================\n",
            "FINAL RESULTS\n",
            "================================================================================\n",
            "\n",
            "Stock: AAPL\n",
            "Date: 2025-10-18 00:52:37\n",
            "\n",
            "Agent Scores:\n",
            "  News Analysis Agent            +0.00\n",
            "  Earnings Analysis Agent        +0.85\n",
            "  Market Signals Agent           -1.00\n",
            "  Risk Assessment Agent          +0.40\n",
            "\n",
            "Final Recommendation: HOLD\n",
            "   Score: +0.00\n",
            "   Confidence: 65%\n",
            "   Quality: 0.60/1.0\n",
            "\n",
            "Analysis:\n",
            "   Strong earnings fundamentals suggest potential for growth, but lack of news and technical signals creates uncertainty. Moderate risk profile indicates a cautious approach is warranted....\n",
            "\n",
            "Key Factors:\n",
            "   1. Strong revenue growth of 15.0%\n",
            "   2. Impressive EPS of $6.42\n",
            "   3. Moderate risk with good risk-adjusted returns\n",
            "\n",
            "================================================================================\n",
            " TEST COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "SUCCESS! integration works! \n",
            "\n",
            "Quick Summary:\n",
            "   Recommendation: HOLD\n",
            "   Final Score: +0.00\n",
            "   Confidence: 65%\n",
            "   Quality: 0.60/1.0\n"
          ]
        }
      ]
    }
  ]
}